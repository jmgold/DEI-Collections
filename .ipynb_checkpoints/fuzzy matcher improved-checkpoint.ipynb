{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to SQLite\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sqliteConnection = sqlite3.connect('DEI Database.db')\n",
    "    cursor = sqliteConnection.cursor()\n",
    "    print(\"Connected to SQLite\")\n",
    "    \n",
    "    sql_query = \"\"\"SELECT *\n",
    "                FROM title_list\n",
    "                \"\"\"\n",
    "    cursor.execute(sql_query)\n",
    "    sqliteConnection.commit()\n",
    "    dei_rows = cursor.fetchall()\n",
    "    cursor.close()\n",
    "except sqlite3.Error as error:\n",
    "    print(\"Failed to run query\", error)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Romance/Erotic Romance</td>\n",
       "      <td>Charlie Adhara</td>\n",
       "      <td>The Wolf at the Door</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Romance/Erotic Romance</td>\n",
       "      <td>Charlie Adhara</td>\n",
       "      <td>The Wolf at Bay</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Romance/Erotic Romance</td>\n",
       "      <td>Charlie Adhara</td>\n",
       "      <td>Thrown to the Wolves</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Romance/Erotic Romance</td>\n",
       "      <td>Charlie Adhara</td>\n",
       "      <td>Wolf in Sheep’s Clothing</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Romance/Erotic Romance</td>\n",
       "      <td>Brea Alepoú</td>\n",
       "      <td>His Bewildered Mate</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>Fiction Anthologies</td>\n",
       "      <td>None</td>\n",
       "      <td>Shades Of Black: Crime And Mystery Stories By ...</td>\n",
       "      <td>2004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>Fiction Anthologies</td>\n",
       "      <td>None</td>\n",
       "      <td>Slay: Stories of the Vampire Noire</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>Fiction Anthologies</td>\n",
       "      <td>None</td>\n",
       "      <td>Transcendent 3: The Year’s Best Transgender Sp...</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>Fiction Anthologies</td>\n",
       "      <td>None</td>\n",
       "      <td>Transcendent 4</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>Fiction Anthologies</td>\n",
       "      <td>None</td>\n",
       "      <td>Walking the Clouds: An Anthology of Indigenous...</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3959 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Genre          Author  \\\n",
       "0     Romance/Erotic Romance  Charlie Adhara   \n",
       "1     Romance/Erotic Romance  Charlie Adhara   \n",
       "2     Romance/Erotic Romance  Charlie Adhara   \n",
       "3     Romance/Erotic Romance  Charlie Adhara   \n",
       "4     Romance/Erotic Romance     Brea Alepoú   \n",
       "...                      ...             ...   \n",
       "3954     Fiction Anthologies            None   \n",
       "3955     Fiction Anthologies            None   \n",
       "3956     Fiction Anthologies            None   \n",
       "3957     Fiction Anthologies            None   \n",
       "3958     Fiction Anthologies            None   \n",
       "\n",
       "                                                  Title    Year  \n",
       "0                                  The Wolf at the Door  2018.0  \n",
       "1                                       The Wolf at Bay  2018.0  \n",
       "2                                  Thrown to the Wolves  2019.0  \n",
       "3                              Wolf in Sheep’s Clothing  2020.0  \n",
       "4                                   His Bewildered Mate  2019.0  \n",
       "...                                                 ...     ...  \n",
       "3954  Shades Of Black: Crime And Mystery Stories By ...  2004.0  \n",
       "3955                 Slay: Stories of the Vampire Noire  2020.0  \n",
       "3956  Transcendent 3: The Year’s Best Transgender Sp...  2018.0  \n",
       "3957                                     Transcendent 4  2019.0  \n",
       "3958  Walking the Clouds: An Anthology of Indigenous...  2012.0  \n",
       "\n",
       "[3959 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"Genre\",\"Author\",\"Title\",\"Year\"]\n",
    "dei_df = pd.DataFrame(dei_rows, columns=column_names)\n",
    "dei_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('Y:\\\\SQL Reports\\\\creds\\\\app_SIC.ini')\n",
    "\n",
    "try:\n",
    "    query = \"\"\"SELECT\n",
    "b.best_title AS title,\n",
    "COALESCE(REPLACE(SPLIT_PART(SPLIT_PART(b.best_author,' (',1),', ',2),'.','')||' '||SPLIT_PART(b.best_author,', ',1),'') AS author,\n",
    "b.publish_year,\n",
    "STRING_AGG(DISTINCT i.location_code,',') AS location\n",
    "FROM\n",
    "sierra_view.bib_record_property b\n",
    "JOIN\n",
    "sierra_view.bib_record_item_record_link l\n",
    "ON\n",
    "b.bib_record_id = l.bib_record_id\n",
    "JOIN\n",
    "sierra_view.item_record i\n",
    "ON\n",
    "l.item_record_id = i.id\n",
    "WHERE\n",
    "b.material_code = 'a'\n",
    "AND b.publish_year >= 2018\n",
    "AND i.location_code ~ '^lin'\n",
    "\n",
    "GROUP BY 1,2,3\n",
    "ORDER BY 1,2\n",
    "    \"\"\"\n",
    "    #variable connection string should be defined in the imported config file\n",
    "    conn = psycopg2.connect( config['db']['connection_string'] )\n",
    "except:\n",
    "    print(\"unable to connect to the database\")\n",
    "    clear_connection()\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)\n",
    "#For now, just storing the data in a variable. We'll use it later.\n",
    "sierra_rows = cursor.fetchall()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Year</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#MeToo and you : everything you need to know a...</td>\n",
       "      <td>Halley Bondy</td>\n",
       "      <td>2021</td>\n",
       "      <td>liny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#wanderlust : the world's 500 most unforgettab...</td>\n",
       "      <td>Sabina Trojanova</td>\n",
       "      <td>2020</td>\n",
       "      <td>linan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(((Semitism))) : being Jewish in America in th...</td>\n",
       "      <td>Jonathan Weisman</td>\n",
       "      <td>2018</td>\n",
       "      <td>lina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(It's great to) suck at something : the unexpe...</td>\n",
       "      <td>Karen Rinaldi</td>\n",
       "      <td>2019</td>\n",
       "      <td>lina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 2 3 Cats</td>\n",
       "      <td>Lesléa Newman</td>\n",
       "      <td>2021</td>\n",
       "      <td>linj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11177</th>\n",
       "      <td>iPhone for seniors for dummies</td>\n",
       "      <td>Dwight Spivey</td>\n",
       "      <td>2018</td>\n",
       "      <td>lina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11178</th>\n",
       "      <td>kimotinâniwiw itwêwina</td>\n",
       "      <td>Melanie Florence</td>\n",
       "      <td>2019</td>\n",
       "      <td>linj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11179</th>\n",
       "      <td>¡Vamos! : let's go eat</td>\n",
       "      <td>1976- author Raúl the Third</td>\n",
       "      <td>2020</td>\n",
       "      <td>linj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11180</th>\n",
       "      <td>¡Vamos! Let's go to the market</td>\n",
       "      <td>1976- author Raúl the Third</td>\n",
       "      <td>2019</td>\n",
       "      <td>linj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11181</th>\n",
       "      <td>¿Podemos ayudar? : niños que ayudan a sus comu...</td>\n",
       "      <td>George Ancona</td>\n",
       "      <td>2019</td>\n",
       "      <td>linj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11182 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title  \\\n",
       "0      #MeToo and you : everything you need to know a...   \n",
       "1      #wanderlust : the world's 500 most unforgettab...   \n",
       "2      (((Semitism))) : being Jewish in America in th...   \n",
       "3      (It's great to) suck at something : the unexpe...   \n",
       "4                                             1 2 3 Cats   \n",
       "...                                                  ...   \n",
       "11177                     iPhone for seniors for dummies   \n",
       "11178                             kimotinâniwiw itwêwina   \n",
       "11179                             ¡Vamos! : let's go eat   \n",
       "11180                     ¡Vamos! Let's go to the market   \n",
       "11181  ¿Podemos ayudar? : niños que ayudan a sus comu...   \n",
       "\n",
       "                            Author  Year Location  \n",
       "0                     Halley Bondy  2021     liny  \n",
       "1                 Sabina Trojanova  2020    linan  \n",
       "2                 Jonathan Weisman  2018     lina  \n",
       "3                    Karen Rinaldi  2019     lina  \n",
       "4                    Lesléa Newman  2021     linj  \n",
       "...                            ...   ...      ...  \n",
       "11177                Dwight Spivey  2018     lina  \n",
       "11178             Melanie Florence  2019     linj  \n",
       "11179  1976- author Raúl the Third  2020     linj  \n",
       "11180  1976- author Raúl the Third  2019     linj  \n",
       "11181                George Ancona  2019     linj  \n",
       "\n",
       "[11182 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names_sierra = [\"Title\", \"Author\", \"Year\", \"Location\"]\n",
    "sierra_df = pd.DataFrame(sierra_rows, columns=column_names_sierra)\n",
    "sierra_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.17818117141723633\n",
      "(2488, 4713)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import re\n",
    "\n",
    "#!pip install ftfy #  text cleaning for decode issues..\n",
    "\n",
    "#from ftfy import fix_text\n",
    "def ngrams(string, n=3):\n",
    "    \"\"\"Takes an input string, cleans it and converts to ngrams. \n",
    "    This script is focussed on cleaning UK company names but can be made generic by removing lines below\"\"\"\n",
    "    string = str(string)\n",
    "    string = string.lower() # lower case\n",
    "    #string = fix_text(string) # fix text\n",
    "    string = string.encode(\"ascii\", errors=\"ignore\").decode() #remove non ascii chars\n",
    "    chars_to_remove = [\")\",\"(\",\".\",\"|\",\"[\",\"]\",\"{\",\"}\",\"'\",\"-\"]\n",
    "    rx = '[' + re.escape(''.join(chars_to_remove)) + ']' #remove punc, brackets etc...\n",
    "    string = re.sub(rx, '', string)\n",
    "    string = re.sub(' +',' ',string).strip() # get rid of multiple spaces and replace with a single\n",
    "    string = ' '+ string +' ' # pad names for ngrams...\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]\n",
    "'''\n",
    "input1_csv = 'Gov Orgs ONS.csv'\n",
    "input1_column = 'Institutions'\n",
    "input2_csv = 'messy org names.csv'\n",
    "input2_column = 'buyer'\n",
    "'''\n",
    "\n",
    "###FIRST TIME RUN - takes about 5 minutes... used to build the matching table\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n",
    "t1 = time.time() # used for timing - can delete\n",
    "##### Create a list of items to match here:\n",
    "dei_names = list(dei_df[\"Author\"].unique()) #unique org names from company watch file\n",
    "#Building the TFIDF off the clean dataset - takes about 5 min\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams)\n",
    "tf_idf_matrix = vectorizer.fit_transform(dei_names)\n",
    "t = time.time()-t1\n",
    "print(\"Time:\", t) # used for timing - can delete\n",
    "print(tf_idf_matrix.shape)\n",
    "\n",
    "import time\n",
    "t1 = time.time()\n",
    "##### Create a list of messy items to match here:\n",
    "sierra_names = list(sierra_df[\"Author\"].unique()) #unique list of names\n",
    "\n",
    "#Creation of vectors for the messy names\n",
    "\n",
    "# #FOR LOADING ONLY - only required if items have been saved previously\n",
    "# vectorizer = pickle.load(open(\"Data/vectorizer.pkl\",\"rb\"))\n",
    "# tf_idf_matrix = pickle.load(open(\"Data/Comp_tfidf.pkl\",\"rb\"))\n",
    "# org_names = pickle.load(open(\"Data/Comp_names.pkl\",\"rb\"))\n",
    "\n",
    "messy_tf_idf_matrix = vectorizer.transform(sierra_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing time = 0.010952\n"
     ]
    }
   ],
   "source": [
    "import nmslib\n",
    "from scipy.sparse import csr_matrix # may not be required \n",
    "from scipy.sparse import rand # may not be required\n",
    "\n",
    "\n",
    "# create a random matrix to index\n",
    "data_matrix = tf_idf_matrix#[0:1000000]\n",
    "\n",
    "# Set index parameters\n",
    "# These are the most important ones\n",
    "M = 80\n",
    "efC = 1000\n",
    "\n",
    "num_threads = 4 # adjust for the number of threads\n",
    "# Intitialize the library, specify the space, the type of the vector and add data points \n",
    "index = nmslib.init(method='simple_invindx', space='negdotprod_sparse_fast', data_type=nmslib.DataType.SPARSE_VECTOR) \n",
    "\n",
    "index.addDataPointBatch(data_matrix)\n",
    "# Create an index\n",
    "start = time.time()\n",
    "index.createIndex() \n",
    "end = time.time() \n",
    "print('Indexing time = %f' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN time total=0.130250 (sec), per query=0.000018 (sec), per query adjusted for thread number=0.000071 (sec)\n"
     ]
    }
   ],
   "source": [
    "# Number of neighbors \n",
    "num_threads = 4\n",
    "K=1\n",
    "query_matrix = messy_tf_idf_matrix\n",
    "start = time.time() \n",
    "query_qty = query_matrix.shape[0]\n",
    "nbrs = index.knnQueryBatch(query_matrix, k = K, num_threads = num_threads)\n",
    "end = time.time() \n",
    "print('kNN time total=%f (sec), per query=%f (sec), per query adjusted for thread number=%f (sec)' % \n",
    "      (end-start, float(end-start)/query_qty, num_threads*float(end-start)/query_qty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\JGOLDS~1\\AppData\\Local\\Temp/ipykernel_3152/2731298502.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmts\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m   \u001b[0moriginal_nm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdei_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmatched_nm\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mdei_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnbrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "mts =[]\n",
    "for i in range(len(nbrs)):\n",
    "  original_nm = dei_names[i]\n",
    "  try:\n",
    "    matched_nm   = dei_names[nbrs[i][0][0]]\n",
    "    conf         = nbrs[i][1][0]\n",
    "  except:\n",
    "    matched_nm   = \"no match found\"\n",
    "    conf         = None\n",
    "  mts.append([original_nm,matched_nm,conf])\n",
    "\n",
    "mts = pd.DataFrame(mts,columns=['dei_Author','matched_Author','conf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = df_CF.merge(mts,left_on='Author',right_on='original_nm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
